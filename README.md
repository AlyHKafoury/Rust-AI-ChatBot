## This is a chatbot experiement in Rust `Axum` and SolidJS
----------------------------------------

### To run this demo you would need to:
 - Download Llama GGML model from https://huggingface.co/
 - Go into __chatbot-backend__ change the model name in `model_path`
 - Install latest rust and cargo binary using rustup
 - Install nodejs 16 and npm
 - Go into the __chatbot-backend__ folder and run `cargo run`
 - Go into the __chatbot-frontend__ folder and run `npm install && npm run dev` 
  
> The model `wizardlm-7b-v1.0-uncensored.ggmlv3.q6_K.bin` ran on commodity hardware with good performance to accuracy ratio.